{"cells":[{"cell_type":"markdown","metadata":{"id":"7com28W55pHk"},"source":["# Nutrition Image Analysis using CNN"]},{"cell_type":"markdown","metadata":{"id":"whbZ5Uw35pHw"},"source":["### Importing Neccessary Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60eg6zmo5pHx"},"outputs":[],"source":["import numpy as np#used for numerical analysis\n","import tensorflow #open source used for both ML and DL for computation\n","from tensorflow.keras.models import Sequential #it is a plain stack of layers\n","from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n","#Dense layer is the regular deeply connected neural network layer\n","from tensorflow.keras.layers import Dense,Flatten\n","#Faltten-used fot flattening the input or change the dimension\n","from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n","#MaxPooling2D-for downsampling the image\n","from keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"id":"vnVt93M05pH0"},"source":["### Image Data Agumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VLZKCTd5pH1"},"outputs":[],"source":["#setting parameter for Image Data agumentation to the training data\n","train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","#Image Data agumentation to the testing data\n","test_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"markdown","metadata":{"id":"kpsHveuq5pH4"},"source":["### Loading our data and performing data agumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Hkc9ffd5pH5","outputId":"f2f3a171-41c1-4f1c-e125-781a47760b45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2626 images belonging to 5 classes.\n","Found 1055 images belonging to 5 classes.\n"]}],"source":["#performing data agumentation to train data\n","x_train = train_datagen.flow_from_directory(\n","    r'C:\\Users\\DELL\\Desktop\\Desk Files\\Nutrition Analysis Using Image Classification\\DataSet\\TRAIN_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n","#performing data agumentation to test data\n","x_test = test_datagen.flow_from_directory(\n","    r'C:\\Users\\DELL\\Desktop\\Desk Files\\Nutrition Analysis Using Image Classification\\DataSet\\TEST_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szwYFmls5pH8","outputId":"be341c75-9d14-446a-c340-8158106647ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"]}],"source":["print(x_train.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SliKn605pH-","outputId":"56cad51d-fcd8-4aca-d0b0-ed3b3c492b7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"]}],"source":["print(x_test.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWWDoRDw5pIA","outputId":"5e13f553-81ed-410f-b80d-35a378902983"},"outputs":[{"data":{"text/plain":["Counter({0: 606, 1: 445, 2: 479, 3: 621, 4: 475})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from collections import Counter as c\n","c(x_train .labels)"]},{"cell_type":"markdown","metadata":{"id":"l3R_JW4b5pIC"},"source":["### Creating the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eejmbWX75pID"},"outputs":[],"source":["# Initializing the CNN\n","classifier = Sequential()\n","\n","# First convolution layer and pooling\n","classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Second convolution layer and pooling\n","classifier.add(Conv2D(32, (3, 3), activation='relu'))\n","\n","# input_shape is going to be the pooled feature maps from the previous convolution layer\n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Flattening the layers\n","classifier.add(Flatten())\n","\n","# Adding a fully connected layer\n","classifier.add(Dense(units=128, activation='relu'))\n","classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNCisXGE5pIE","outputId":"3753599e-dc4d-4005-b574-50e3c2efc1fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 62, 62, 32)        896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6272)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               802944    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 813,733\n","Trainable params: 813,733\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["classifier.summary()#summary of our model"]},{"cell_type":"markdown","metadata":{"id":"VTpQ5NR95pIF"},"source":["### Compiling the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0sf79GD5pIH"},"outputs":[],"source":["# Compiling the CNN\n","# categorical_crossentropy for more than 2\n","classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "]},{"cell_type":"markdown","metadata":{"id":"s6CAbE5c5pIL"},"source":["## Fitting the model"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"l8JLV16x5pIM","outputId":"69497dfa-dd17-4320-9c4d-b88e659ff75e"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-10-386df932e001>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/20\n","526/526 [==============================] - 38s 73ms/step - loss: 0.1635 - accuracy: 0.9368 - val_loss: 0.2983 - val_accuracy: 0.9526\n","Epoch 2/20\n","526/526 [==============================] - 24s 46ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.0707 - val_accuracy: 0.9725\n","Epoch 3/20\n","526/526 [==============================] - 22s 42ms/step - loss: 3.9420e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9905\n","Epoch 4/20\n","526/526 [==============================] - 22s 41ms/step - loss: 1.4107e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9877\n","Epoch 5/20\n","526/526 [==============================] - 22s 41ms/step - loss: 4.6145e-05 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9820\n","Epoch 6/20\n","526/526 [==============================] - 22s 41ms/step - loss: 2.9885e-05 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9820\n","Epoch 7/20\n","526/526 [==============================] - 22s 41ms/step - loss: 0.0383 - accuracy: 0.9916 - val_loss: 0.3705 - val_accuracy: 0.8493\n","Epoch 8/20\n","526/526 [==============================] - 21s 41ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 9/20\n","526/526 [==============================] - 22s 42ms/step - loss: 1.0176e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n","Epoch 10/20\n","526/526 [==============================] - 22s 41ms/step - loss: 4.7693e-05 - accuracy: 1.0000 - val_loss: 7.4272e-04 - val_accuracy: 1.0000\n","Epoch 11/20\n","526/526 [==============================] - 21s 41ms/step - loss: 1.4932e-05 - accuracy: 1.0000 - val_loss: 8.4048e-04 - val_accuracy: 1.0000\n","Epoch 12/20\n","526/526 [==============================] - 22s 42ms/step - loss: 7.2105e-06 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 13/20\n","526/526 [==============================] - 21s 41ms/step - loss: 4.4252e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n","Epoch 14/20\n","526/526 [==============================] - 22s 42ms/step - loss: 6.8033e-06 - accuracy: 1.0000 - val_loss: 9.4469e-04 - val_accuracy: 1.0000\n","Epoch 15/20\n","526/526 [==============================] - 23s 43ms/step - loss: 2.1526e-06 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 16/20\n","526/526 [==============================] - 22s 42ms/step - loss: 1.4028e-06 - accuracy: 1.0000 - val_loss: 4.9155e-04 - val_accuracy: 1.0000\n","Epoch 17/20\n","526/526 [==============================] - 22s 43ms/step - loss: 6.5178e-07 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 18/20\n","526/526 [==============================] - 23s 43ms/step - loss: 7.7361e-07 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 19/20\n","526/526 [==============================] - 22s 42ms/step - loss: 4.4809e-07 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 20/20\n","526/526 [==============================] - 22s 43ms/step - loss: 2.0291e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x26946aa4a30>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["classifier.fit_generator(\n","        generator=x_train,steps_per_epoch = len(x_train),\n","        epochs=20, validation_data=x_test,validation_steps = len(x_test))# No of images in test set"]},{"cell_type":"markdown","metadata":{"id":"icM7Nuc35pIO"},"source":["### Saving our model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAJYdsrl5pIQ"},"outputs":[],"source":["# Save the model\n","classifier.save('nutrition.h5')"]},{"cell_type":"markdown","metadata":{"id":"wnKeLh5m5pIR"},"source":["### Predicting our results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tJkyuyz5pIR"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from keras.preprocessing import image\n","model = load_model(\"nutrition.h5\") #loading the model for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSQ6tnsR5pIc","outputId":"0ffb0001-eb70-42f8-d2e9-93cfde566c05"},"outputs":[{"data":{"text/plain":["array([3], dtype=int64)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["img = image.load_img(r\"C:\\Users\\DELL\\Desktop\\Desk Files\\Nutrition Analysis Using Image Classification\\Sample_Images\\Test_Image5.jpg\",\n","                     grayscale=False,target_size= (64,64))#loading of the image\n","x = image.img_to_array(img)#image to array\n","x = np.expand_dims(x,axis = 0)#changing the shape\n","pred = model.predict_classes(x)#predicting the classes\n","pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EazH0bQ05pIc","outputId":"4ee9e9f9-f628-447c-80a9-9d4a86020316"},"outputs":[{"data":{"text/plain":["'PINEAPPLE'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n","result=str(index[pred[0]])\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImD8ff9z5pIe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psfuX7AC5pIe"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}